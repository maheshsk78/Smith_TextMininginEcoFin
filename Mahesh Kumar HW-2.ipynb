{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mahesh Kumar\n",
    "# Q1 (Regex)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['02/20/2019']\n",
      "['3/13/2019']\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "#Sentences\n",
    "sent1 = \"Today’s date is 02/20/2019\"\n",
    "sent2 = \"Today the date is 3/13/2019\"\n",
    "\n",
    "#Finding and printing pattern using regular expression\n",
    "print(re.findall(r'(\\d+/\\d+/\\d+)',sent1))\n",
    "print(re.findall(r'(\\d+/\\d+/\\d+)',sent2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Q2 (Regex)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['12/5/2oo7']\n",
      "['6/5/2017']\n",
      "['1/1/20o7']\n",
      "['10/1/2o09']\n",
      "['1o/1/2o09']\n"
     ]
    }
   ],
   "source": [
    "#Sentences\n",
    "sent3 = \"Today’s date is 12/5/2oo7\"\n",
    "sent4 = \"Today’s date is 6/5/2017\"\n",
    "sent5 = \"Today’s date is 1/1/20o7\"\n",
    "sent6 = \"Today’s date is 10/1/2o09\"\n",
    "sent7 = \"Today’s date is 1o/1/2o09\"#if 'o' appears in dd \n",
    "\n",
    "#Finding and printing pattern using regular expression\n",
    "print(re.findall(r'(\\w+/\\w+/\\w+)',sent3))\n",
    "print(re.findall(r'(\\w+/\\w+/\\w+)',sent4))\n",
    "print(re.findall(r'(\\w+/\\w+/\\w+)',sent5))\n",
    "print(re.findall(r'(\\w+/\\w+/\\w+)',sent6))\n",
    "print(re.findall(r'(\\w+/\\w+/\\w+)',sent7))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Q3 (Regex)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['AAPL', 'BAC', 'GE']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Sentence\n",
    "sent8 = \"The stocks AAPL, BAC, and GE rallied in the market last week\"\n",
    "\n",
    "#Finding and printing pattern using regular expression\n",
    "re.findall(r'([A-Z]{2,})',sent8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Q4 (Regex)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Jerome Powell', 'Mario Draghi']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Sentence\n",
    "sent9 = \"The markets listened to what Jerome Powell was going to say following the press conference with Mario Draghi\"\n",
    "\n",
    "#Finding and printing pattern using regular expression\n",
    "re.findall(r'([A-Z][a-z]+\\s[A-Z][a-z]+)',sent9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Q5 (Tfidf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>statements</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2/4/1994</td>\n",
       "      <td>Chairman Alan Greenspan announced today that t...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       date                                         statements\n",
       "0  2/4/1994  Chairman Alan Greenspan announced today that t..."
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Load data\n",
    "import pandas as pd\n",
    "df=pd.read_csv(\"FOMC_minutes.csv\")\n",
    "df.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>statements</th>\n",
       "      <th>noise_free_text</th>\n",
       "      <th>sent_without_digits</th>\n",
       "      <th>sent_without_stop</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2/4/1994</td>\n",
       "      <td>Chairman Alan Greenspan announced today that t...</td>\n",
       "      <td>chairman alan greenspan announced today that t...</td>\n",
       "      <td>chairman alan greenspan announced today that t...</td>\n",
       "      <td>chairman alan greenspan announced today federa...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       date                                         statements  \\\n",
       "0  2/4/1994  Chairman Alan Greenspan announced today that t...   \n",
       "\n",
       "                                     noise_free_text  \\\n",
       "0  chairman alan greenspan announced today that t...   \n",
       "\n",
       "                                 sent_without_digits  \\\n",
       "0  chairman alan greenspan announced today that t...   \n",
       "\n",
       "                                   sent_without_stop  \n",
       "0  chairman alan greenspan announced today federa...  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Noise Removal\n",
    "\n",
    "#Case-sensitivity - convert token to lower case\n",
    "df['noise_free_text'] = df['statements'].str.lower()\n",
    "\n",
    "#Punctuation - remove punctuations from string terms in dataframe\n",
    "df['noise_free_text'] = df['noise_free_text'].str.replace('[^\\w\\s]','')\n",
    "\n",
    "#Other Noise - Remove numbers from string terms in dataframe\n",
    "df['sent_without_digits'] = df['noise_free_text'].str.replace('\\d+', '')\n",
    "\n",
    "# Import stopwords with nltk\n",
    "from nltk.corpus import stopwords\n",
    "stop = stopwords.words('english')\n",
    "\n",
    "#Remove stopwords from string terms in dataframe\n",
    "df['sent_without_stop'] = df['sent_without_digits'].apply(lambda x: ' '.join([word for word in x.split() if word not in (stop)]))\n",
    "df.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>statements</th>\n",
       "      <th>noise_free_text</th>\n",
       "      <th>sent_without_digits</th>\n",
       "      <th>sent_without_stop</th>\n",
       "      <th>text_lemmatized</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2/4/1994</td>\n",
       "      <td>Chairman Alan Greenspan announced today that t...</td>\n",
       "      <td>chairman alan greenspan announced today that t...</td>\n",
       "      <td>chairman alan greenspan announced today that t...</td>\n",
       "      <td>chairman alan greenspan announced today federa...</td>\n",
       "      <td>chairman alan greenspan announced today federa...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       date                                         statements  \\\n",
       "0  2/4/1994  Chairman Alan Greenspan announced today that t...   \n",
       "\n",
       "                                     noise_free_text  \\\n",
       "0  chairman alan greenspan announced today that t...   \n",
       "\n",
       "                                 sent_without_digits  \\\n",
       "0  chairman alan greenspan announced today that t...   \n",
       "\n",
       "                                   sent_without_stop  \\\n",
       "0  chairman alan greenspan announced today federa...   \n",
       "\n",
       "                                     text_lemmatized  \n",
       "0  chairman alan greenspan announced today federa...  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Importing whitespace tokenizer and Wordnet Lemmatizer from nltk\n",
    "import nltk\n",
    "w_tokenizer = nltk.tokenize.WhitespaceTokenizer()\n",
    "lemmatizer = nltk.stem.WordNetLemmatizer()\n",
    "\n",
    "def lemmatize_text(text):\n",
    "    return [lemmatizer.lemmatize(w) for w in w_tokenizer.tokenize(text)]\n",
    "\n",
    "#Normalization - lemming\n",
    "df['text_lemmatized'] = df.sent_without_stop.apply(lemmatize_text)\n",
    "\n",
    "#Combining lemmatized tokens into string and rewriting column 'text_lemmatized' in the datatframe\n",
    "df['text_lemmatized'] = df['text_lemmatized'].str.join(\" \") \n",
    "df.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Deploying Tf-idf method\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "v = TfidfVectorizer()\n",
    "x = v.fit_transform(df['text_lemmatized'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>aaaaaarated</th>\n",
       "      <th>abate</th>\n",
       "      <th>abating</th>\n",
       "      <th>ability</th>\n",
       "      <th>abroad</th>\n",
       "      <th>abroadcontinue</th>\n",
       "      <th>absence</th>\n",
       "      <th>absent</th>\n",
       "      <th>accelerated</th>\n",
       "      <th>accelerates</th>\n",
       "      <th>...</th>\n",
       "      <th>winter</th>\n",
       "      <th>work</th>\n",
       "      <th>worker</th>\n",
       "      <th>working</th>\n",
       "      <th>would</th>\n",
       "      <th>written</th>\n",
       "      <th>year</th>\n",
       "      <th>yellen</th>\n",
       "      <th>yet</th>\n",
       "      <th>york</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.065221</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.074322</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.093893</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>160</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>161</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>162</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>163</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.052157</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>164</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.049110</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>165 rows × 1498 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     aaaaaarated  abate  abating  ability  abroad  abroadcontinue  absence  \\\n",
       "0            0.0    0.0      0.0      0.0     0.0             0.0      0.0   \n",
       "1            0.0    0.0      0.0      0.0     0.0             0.0      0.0   \n",
       "2            0.0    0.0      0.0      0.0     0.0             0.0      0.0   \n",
       "3            0.0    0.0      0.0      0.0     0.0             0.0      0.0   \n",
       "4            0.0    0.0      0.0      0.0     0.0             0.0      0.0   \n",
       "..           ...    ...      ...      ...     ...             ...      ...   \n",
       "160          0.0    0.0      0.0      0.0     0.0             0.0      0.0   \n",
       "161          0.0    0.0      0.0      0.0     0.0             0.0      0.0   \n",
       "162          0.0    0.0      0.0      0.0     0.0             0.0      0.0   \n",
       "163          0.0    0.0      0.0      0.0     0.0             0.0      0.0   \n",
       "164          0.0    0.0      0.0      0.0     0.0             0.0      0.0   \n",
       "\n",
       "     absent  accelerated  accelerates  ...  winter  work  worker  working  \\\n",
       "0       0.0          0.0          0.0  ...     0.0   0.0     0.0      0.0   \n",
       "1       0.0          0.0          0.0  ...     0.0   0.0     0.0      0.0   \n",
       "2       0.0          0.0          0.0  ...     0.0   0.0     0.0      0.0   \n",
       "3       0.0          0.0          0.0  ...     0.0   0.0     0.0      0.0   \n",
       "4       0.0          0.0          0.0  ...     0.0   0.0     0.0      0.0   \n",
       "..      ...          ...          ...  ...     ...   ...     ...      ...   \n",
       "160     0.0          0.0          0.0  ...     0.0   0.0     0.0      0.0   \n",
       "161     0.0          0.0          0.0  ...     0.0   0.0     0.0      0.0   \n",
       "162     0.0          0.0          0.0  ...     0.0   0.0     0.0      0.0   \n",
       "163     0.0          0.0          0.0  ...     0.0   0.0     0.0      0.0   \n",
       "164     0.0          0.0          0.0  ...     0.0   0.0     0.0      0.0   \n",
       "\n",
       "     would  written      year  yellen  yet      york  \n",
       "0      0.0      0.0  0.000000     0.0  0.0  0.000000  \n",
       "1      0.0      0.0  0.000000     0.0  0.0  0.000000  \n",
       "2      0.0      0.0  0.000000     0.0  0.0  0.000000  \n",
       "3      0.0      0.0  0.065221     0.0  0.0  0.074322  \n",
       "4      0.0      0.0  0.000000     0.0  0.0  0.093893  \n",
       "..     ...      ...       ...     ...  ...       ...  \n",
       "160    0.0      0.0  0.000000     0.0  0.0  0.000000  \n",
       "161    0.0      0.0  0.000000     0.0  0.0  0.000000  \n",
       "162    0.0      0.0  0.000000     0.0  0.0  0.000000  \n",
       "163    0.0      0.0  0.052157     0.0  0.0  0.000000  \n",
       "164    0.0      0.0  0.049110     0.0  0.0  0.000000  \n",
       "\n",
       "[165 rows x 1498 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Displaying Tf-idf matrix as a dataframe\n",
    "tfidf_dataframe=pd.DataFrame(columns=v.get_feature_names(),data=x.toarray())\n",
    "tfidf_dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#What is the size of the resulting matrix? What is the maximum value and the lowest value of the matrix?\n",
    "#Interpret the resulting matrix. What do the rows and columns represent? What does each value in the matrix \n",
    "#represent? What does it mean when a word has the highest TF-IDF value across the corpus? What does the lowest value represent?\n",
    "#=>(See answers at the end)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(165, 1498)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#printing shape of the dataframe\n",
    "tfidf_dataframe.shape "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aaaaaarated    0.0\n",
      "abate          0.0\n",
      "abating        0.0\n",
      "ability        0.0\n",
      "abroad         0.0\n",
      "              ... \n",
      "written        0.0\n",
      "year           0.0\n",
      "yellen         0.0\n",
      "yet            0.0\n",
      "york           0.0\n",
      "Length: 1498, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "tfidf_dataframe.min(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "facility           0.441654\n",
       "bank               0.409845\n",
       "maturity           0.405763\n",
       "arrangement        0.404926\n",
       "central            0.373854\n",
       "                     ...   \n",
       "efficacy           0.047662\n",
       "turn               0.047662\n",
       "contingent         0.047662\n",
       "preset             0.047662\n",
       "stillincreasing    0.047662\n",
       "Length: 1498, dtype: float64"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidf_dataframe.max().sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "####**********INTERPRETATION**********\n",
    "\n",
    "#The resulting Tfidf matrix is 165 x 1498 (rows x columns) in size.\n",
    "#This means that there are 165 documents in the corpus FOMC_minutes and after preprocessing the documents, the \n",
    "#number of tokens found throughout the text equals 1498.\n",
    "#Such as: \"banking\", \"facility\", etc. (see output 16)\n",
    "\n",
    "#The 'v.get_feature_names()' gives a union set of all tokens in the corpus and they have been input as \n",
    "#column names to the dataframe 'tfidf_dataframe'\n",
    "\n",
    "#Tfidf algorithm penalizes words with higher frequency across the corpus. Thus tfidf identifies 'important' terms \n",
    "#in a document based on its inter & intra document count. \n",
    "\n",
    "#The minimum value is 0 (for words such as: ability, abroad, written, year, etc).\n",
    "#The top 3 maximum values are:\n",
    "##(1)facility           0.441654\n",
    "##(2)bank               0.409845\n",
    "##(3)maturity           0.405763\n",
    "\n",
    "#A value of 0 implies that either the term/token occurs in all the documents or its frequency within that document is 0\n",
    "#i.e. =>> [tf = 0] OR [idf = 0]\n",
    "# tf = frequency of term in that document\n",
    "# idf = log (total # of document / # of documents with that particular term)\n",
    "#log(1) = 0\n",
    "\n",
    "#Whereas, a maximum value would imply that both tf and idf are non-zero (as high as possible)\n",
    "\n",
    "#Since min & max is dependent on the multiplication of two terms - to look at tf_idf more technically, we'll need to take\n",
    "#the first differential of the equation (that defines tfidf) and solve it using an inequality while making sure that the \n",
    "#second differential is greater than 0 (in order to maximize the output)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
